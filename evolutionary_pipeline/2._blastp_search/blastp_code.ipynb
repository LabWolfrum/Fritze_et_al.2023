{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11431557",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change .xlsx to .txt\n",
    "# Import the required library (pandas)\n",
    "import pandas as pd\n",
    "\n",
    "# Load the excel file\n",
    "df = pd.read_excel(\"metazoa.xlsx\")\n",
    "\n",
    "# Extract the first column of the excel\n",
    "first_column = df[df.columns[0]]\n",
    "\n",
    "# Write the extracted data to a text file, separating each row with a \";\"\n",
    "with open(\"output.txt\", \"w\") as file:\n",
    "    for item in first_column:\n",
    "        file.write(str(item) + \";\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a95e8676",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'example' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4548\\716570096.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m#Entrez e-mail has to be registered in NCBI and inserted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mEntrez\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0memail\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexample\u001b[0m\u001b[1;33m@\u001b[0m\u001b[0mexample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"organism.txt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'example' is not defined"
     ]
    }
   ],
   "source": [
    "#General note: \n",
    "#Since NCBI Entrez seems to be unstable for the download.\n",
    "#Two errors often apeared:\n",
    "#1. breack down of program, it is recomended to restart the code and edit manually before the \"output.txt\" file\n",
    "#2. Sometimes e-mail adress in \"Entrez.email\" is giving an error message, \n",
    "#it is recomended to out-comment this part normally it works afterwords\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#protein of interest\n",
    "USH1G=\"MNDQYHRAARDGYLELLKEATRKELNAPDEDGMTPTLWAAYHGNLESLRLIVSRGGDPDKCDIWGNTPLHLAASNGHLHCLSFLVSFGANIWCLDNDYHTPLDMAAMKGHMECVRYLDSIAAKQSSLNPKLVGKLKDKAFREAERRIRECAKLQRRHHERMERRYRRELAERSDTLSFSSLTSSTLSRRLQHLALGSHLPYSQATLHGTARGKTKMQKKLERRKQGGEGTFKVSEDGRKSARSLSGLQLGSDVMFVRQGTYANPKEWGRAPLRDMFLSDEDSVSRATLAAEPAHSEVSTDSGHDSLFTRPGLGTMVFRRNYLSSGLHGLGREDGGLDGVGAPRGRLQSSPSLDDDSLGSANSLQDRSCGEELPWDELDLGLDEDLEPETSPLETFLASLHMEDFAALLRQEKIDLEALMLCSDLDLRSISVPLGPRKKILGAVRRRRQAMERPPALEDTEL\"\n",
    "from Bio.Blast import NCBIWWW\n",
    "from Bio.Blast import NCBIXML\n",
    "from Bio import Entrez, SeqIO\n",
    "import requests\n",
    "#Entrez e-mail has to be registered in NCBI and inserted\n",
    "Entrez.email=example.example@example.com\n",
    "\n",
    "with open(\"organism.txt\", \"r\") as f:\n",
    "    organisms_string = f.read()\n",
    "organisms_list = organisms_string.split(\";\")\n",
    "\n",
    "for i in organisms_list:\n",
    "    # Specify the organism you want to search for\n",
    "    organism = i\n",
    "\n",
    "    # Use the esearch function to search for the organism in the taxonomy database\n",
    "    result = Entrez.esearch(db=\"taxonomy\", term=organism)\n",
    "    record = Entrez.read(result)\n",
    "\n",
    "    # Extract the taxonomy ID of the organism\n",
    "    taxonomy_id = record[\"IdList\"][0]\n",
    "\n",
    "    # Use the efetch function to retrieve the nomenclature of the organism\n",
    "    result = Entrez.efetch(db=\"taxonomy\", id=taxonomy_id, retmode=\"xml\")\n",
    "    record = Entrez.read(result)\n",
    "\n",
    "    # Extract the nomenclature of the organism\n",
    "    nomenclature = record[0][\"ScientificName\"]\n",
    "\n",
    "\n",
    "    # Perform BLASTP search on NCBI using USH1G gene as input and organism = homo sapiens (taxonomy id 9606)\n",
    "    result_handle = NCBIWWW.qblast(\"blastp\", \"nr\", USH1G, entrez_query=\"txid\"+taxonomy_id+\"[Organism]\")\n",
    "\n",
    "    # Parse the BLASTP output\n",
    "    blast_records = NCBIXML.parse(result_handle)\n",
    "\n",
    "    # Initialize variables to store the lowest e-value, the highest percent identity and the corresponding record\n",
    "    lowest_evalue = float(\"inf\")\n",
    "    highest_identity = 0\n",
    "    lowest_record = None\n",
    "    fasta_seq = \"\"\n",
    "\n",
    "    # Iterate through each record in the BLASTP output\n",
    "    for blast_record in blast_records:\n",
    "        for alignment in blast_record.alignments:\n",
    "            for hsp in alignment.hsps:\n",
    "                # Check if the current e-value is less than the current lowest e-value\n",
    "                if hsp.expect < lowest_evalue and (hsp.identities / hsp.align_length)*100 > highest_identity:\n",
    "                    lowest_evalue = hsp.expect\n",
    "                    highest_identity = (hsp.identities / hsp.align_length)*100\n",
    "                    lowest_record = hsp\n",
    "                    title_fasta_pre=alignment.title\n",
    "                    #print(title_fasta_pre)\n",
    "                    title_fasta=title_fasta_pre.split(\";\")[0]\n",
    "            \n",
    "                    title_fasta_2=title_fasta.split(\"|\")[1]\n",
    "                    #print(title_fasta_2)\n",
    "                    \n",
    "    handle = Entrez.efetch(db=\"protein\", id=title_fasta_2, rettype=\"fasta\")\n",
    "    record = SeqIO.read(handle, \"fasta\")\n",
    "\n",
    "    fasta_code = str(record.seq)\n",
    "                    \n",
    "                \n",
    "\n",
    "    if lowest_record is not None:\n",
    "            # Extract the FASTA sequence of the alignment\n",
    "            fasta_seq = \">\" + title_fasta_2 + \"\\n\" + fasta_code + \"\\n\"\n",
    "            # Create the output file name by combining the taxonomy ID and fasta extension\n",
    "            output_file = taxonomy_id+\".fasta\"\n",
    "            # Write the FASTA sequence to a file\n",
    "            with open(output_file, \"w\") as f:\n",
    "                f.write(fasta_seq)\n",
    "    else:\n",
    "        print(\"No records found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e12b476",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merges all .fasta into one .txt\n",
    "\n",
    "import os\n",
    "\n",
    "def merge_fasta_files():\n",
    "    # Get the list of all '.fasta' files in the current directory\n",
    "    fasta_files = [file for file in os.listdir() if file.endswith('.fasta')]\n",
    "\n",
    "    # Create a new file to write the contents of all '.fasta' files\n",
    "    with open('fasta_merged.txt', 'w') as out_file:\n",
    "        for file in fasta_files:\n",
    "            with open(file, 'r') as fasta:\n",
    "                out_file.write(fasta.read())\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    merge_fasta_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0479027",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005b4c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d097e835",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ce39b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efdbde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593b753e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc2783c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
